{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_Numpy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLwk8WG4Z0Ds"
      },
      "source": [
        "# **Assignment 4 - MNIST classifier with various training knobs using numpy**\n",
        "\n",
        "### Arpitha Gurumurthy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXxmQ7vTYM8_"
      },
      "source": [
        "### **Data :** \n",
        "Kaggle dataset https://www.kaggle.com/c/digit-recognizer/data </br>\n",
        "The files train.csv and test.csv contains gray-scale images of hand-drawn digits 0 through 9.\n",
        "\n",
        "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
        "\n",
        "* The train.csv has 785 columns. The first column called \"label\", is the hand drawn digit. The rest of the columns contain the pixel-values of the associated image.\n",
        "* The test.csv is the same as the training set, except that it does not contain the \"label\" column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iHRIijUZtsP"
      },
      "source": [
        "## **Data Collection :** \n",
        "Here, we are  authorizing google drive to access and download the kaggle datasets and import it to the colab as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lrfHzo_awJp",
        "outputId": "28514d9d-1fb7-472d-ff34-14e284a04661"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOWuq0t7a8EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1398e959-8ec7-44c0-fdc7-f519adfd3798"
      },
      "source": [
        "%cd /content/gdrive/My Drive/258_HW3/digit_recognizer_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/258_HW3/digit_recognizer_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hLcxq2Laj3L"
      },
      "source": [
        "## Required only on the first run to get the datasets on to the drive\n",
        "## !kaggle competitions download -c digit-recognizer\n",
        "## !mkdir digit_recognizer_data \n",
        "## !mv *.zip digit_recognizer_data/\n",
        "## %cd digit_recognizer_data/\n",
        "## !unzip test.csv.zip\n",
        "## !unzip train.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BADsAmRxrKH"
      },
      "source": [
        "## Importing the required libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "##reading the csv into the dataframe 'train'\n",
        "train = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxEvdqhM6eFj"
      },
      "source": [
        "##Split the dataframe into train and test in the ratio 80 and 20 - train and test\n",
        "##Set the random seed\n",
        "np.random.seed(2)\n",
        "random_seed = 2\n",
        "X_train, X_test = train_test_split(train, test_size = 0.2, random_state=random_seed)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVkD7ACcdwyo"
      },
      "source": [
        "## **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UBvRJlx8uL3",
        "outputId": "9d2544c2-9b32-4712-af9b-f53d9f500bca"
      },
      "source": [
        "##Check for the shape of train data\n",
        "X_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33600, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "MlW8CET2bwUQ",
        "outputId": "e97f3c7f-a22a-4074-c59f-9d42e0930535"
      },
      "source": [
        "##Understanding the training data\n",
        "X_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21250</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20334</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29647</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3220</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5293</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "21250      2       0       0       0  ...         0         0         0         0\n",
              "20334      3       0       0       0  ...         0         0         0         0\n",
              "29647      2       0       0       0  ...         0         0         0         0\n",
              "3220       9       0       0       0  ...         0         0         0         0\n",
              "5293       0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZbABtfy8xJa",
        "outputId": "87d76780-4d36-443e-8c91-de0e780f4a03"
      },
      "source": [
        "##Check for the shape of test data\n",
        "X_test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8400, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "5agVcmAd3r37",
        "outputId": "628ba0c6-c6d5-4d56-84e1-fd04658d9075"
      },
      "source": [
        "##Check for the shape of test data\n",
        "X_test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38732</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3686</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30090</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31205</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11331</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "38732      6       0       0       0  ...         0         0         0         0\n",
              "3686       9       0       0       0  ...         0         0         0         0\n",
              "30090      5       0       0       0  ...         0         0         0         0\n",
              "31205      7       0       0       0  ...         0         0         0         0\n",
              "11331      9       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CmdrFa-iPOQ",
        "outputId": "7e27b1e8-9782-49b5-8bd7-8b6630ad8bfd"
      },
      "source": [
        "##Checking for null values in the training set\n",
        "X_train.isna().sum().describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    785.0\n",
              "mean       0.0\n",
              "std        0.0\n",
              "min        0.0\n",
              "25%        0.0\n",
              "50%        0.0\n",
              "75%        0.0\n",
              "max        0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfQHe2ajiYKL",
        "outputId": "d25a784e-58e9-44fc-fe27-5b44f4320dab"
      },
      "source": [
        "##Checking for null values in the test set\n",
        "X_test.isna().sum().describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    785.0\n",
              "mean       0.0\n",
              "std        0.0\n",
              "min        0.0\n",
              "25%        0.0\n",
              "50%        0.0\n",
              "75%        0.0\n",
              "max        0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfpfxIhQigEv"
      },
      "source": [
        "There are no null values in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "GWvurJL_b8Ie",
        "outputId": "cacdd93a-d77f-437c-835f-2f3905bf972d"
      },
      "source": [
        "##Countplot to check the data distribtion\n",
        "sns.countplot(X_train['label'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f71787e2750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XKJEvUBeJ94"
      },
      "source": [
        "From the above countplot, we can see that the dataset is mostly balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFJ3PfBaeTqF"
      },
      "source": [
        "## **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccOtvvYAynv3"
      },
      "source": [
        "##Converting the dataset to numpy array\n",
        "train_np = X_train.to_numpy()\n",
        "test_np = X_test.to_numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHkoH0gKzEyQ",
        "outputId": "be7defd5-ffe2-40e7-d64e-0884c3654d39"
      },
      "source": [
        "test_np[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6, 0, 0, ..., 0, 0, 0],\n",
              "       [9, 0, 0, ..., 0, 0, 0],\n",
              "       [5, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [3, 0, 0, ..., 0, 0, 0],\n",
              "       [7, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LMf9vA2zNX3",
        "outputId": "abc4a5a6-01d1-47ff-b424-b3edad031dfe"
      },
      "source": [
        "test_np[test_np==255]\n",
        "test_np.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8400, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hygn1rn_etas"
      },
      "source": [
        "The images of the MNIST dataset are greyscale and the pixel values range between 0 to 255. We will map these values into an interval from [0.01, 1] by multiplying each pixel by 0.99 / 255 and adding 0.01 to the result. This way, we avoid 0 values as inputs, which are capable of preventing weight updates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY1Y7_PAzVoE"
      },
      "source": [
        "fac = 0.99 / 255\n",
        "train_imgs = np.asfarray(train_np[:, 1:]) * fac + 0.01\n",
        "test_imgs = np.asfarray(test_np[:, 1:]) * fac + 0.01\n",
        "\n",
        "train_labels = np.asfarray(train_np[:, :1])\n",
        "test_labels = np.asfarray(test_np[:, :1])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oz6IbuwfNHj"
      },
      "source": [
        "We need the labels in a one-hot representation. We have 10 digits from 0 to 9, i.e. lr = np.arange(10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXG9rxnizebl",
        "outputId": "5ea679f8-8b3b-4381-9a85-ab85a44108e2"
      },
      "source": [
        "lr = np.arange(10)\n",
        "##Printing out the values\n",
        "for label in range(10):\n",
        "    one_hot = (lr==label).astype(np.int)\n",
        "    print(\"label\", label, \"in one-hot representation: \", one_hot)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label 0 in one-hot representation:  [1 0 0 0 0 0 0 0 0 0]\n",
            "label 1 in one-hot representation:  [0 1 0 0 0 0 0 0 0 0]\n",
            "label 2 in one-hot representation:  [0 0 1 0 0 0 0 0 0 0]\n",
            "label 3 in one-hot representation:  [0 0 0 1 0 0 0 0 0 0]\n",
            "label 4 in one-hot representation:  [0 0 0 0 1 0 0 0 0 0]\n",
            "label 5 in one-hot representation:  [0 0 0 0 0 1 0 0 0 0]\n",
            "label 6 in one-hot representation:  [0 0 0 0 0 0 1 0 0 0]\n",
            "label 7 in one-hot representation:  [0 0 0 0 0 0 0 1 0 0]\n",
            "label 8 in one-hot representation:  [0 0 0 0 0 0 0 0 1 0]\n",
            "label 9 in one-hot representation:  [0 0 0 0 0 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM1BsyCffZTa"
      },
      "source": [
        "We are ready now to turn our labelled images into one-hot representations. Instead of zeroes and one, we create 0.01 and 0.99.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK7ojDiozkfj"
      },
      "source": [
        "image_size = 28 \n",
        "no_of_different_labels = 10\n",
        "lr = np.arange(no_of_different_labels)\n",
        "\n",
        "# transform labels into one hot representation\n",
        "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
        "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
        "\n",
        "# we don't want zeroes and ones in the labels \n",
        "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
        "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
        "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
        "test_labels_one_hot[test_labels_one_hot==1] = 0.99"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds0F9o5ugBR2"
      },
      "source": [
        "### Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "HVPzBWw7zvf2",
        "outputId": "ba10d24a-a412-4862-d4a8-16917c9efd50"
      },
      "source": [
        "img = train_imgs[0].reshape((28,28))\n",
        "plt.imshow(img, cmap=\"Pastel1\")\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WCX_rpbluly"
      },
      "source": [
        "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
        "Y_train = train[\"label\"]\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "Y_train = to_categorical(Y_train, num_classes = 10)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "3ce-ThsGlxTa",
        "outputId": "24c6d9ca-e171-4c4c-d931-51a7a2577926"
      },
      "source": [
        "##Checking the output format\n",
        "plt.title(Y_train[7])\n",
        "plt.plot(Y_train[7])\n",
        "plt.xticks(range(10));"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suoDyMf1gUU3"
      },
      "source": [
        "## Defining the neural network for our classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCO-vZqw0bL4"
      },
      "source": [
        "from scipy.stats import truncnorm\n",
        "\n",
        "##Activation function\n",
        "@np.vectorize\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.e ** -x)\n",
        "    # return np.maximum(0,x)\n",
        "\n",
        "activation_function = sigmoid\n",
        "\n",
        "##normalizing the input\n",
        "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
        "    return truncnorm((low - mean) / sd, \n",
        "                     (upp - mean) / sd, \n",
        "                     loc=mean, \n",
        "                     scale=sd)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, \n",
        "                 no_of_in_nodes, \n",
        "                 no_of_out_nodes, \n",
        "                 no_of_hidden_nodes,\n",
        "                 learning_rate):\n",
        "        self.no_of_in_nodes = no_of_in_nodes\n",
        "        self.no_of_out_nodes = no_of_out_nodes\n",
        "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
        "        self.learning_rate = learning_rate \n",
        "        self.create_weight_matrices()\n",
        "\n",
        "    ##Weight initialization       \n",
        "    def create_weight_matrices(self):\n",
        "        rad = 1 / np.sqrt(self.no_of_in_nodes)\n",
        "        X = truncated_normal(mean=0, \n",
        "                             sd=1, \n",
        "                             low=-rad, \n",
        "                             upp=rad)\n",
        "        self.wih = X.rvs((self.no_of_hidden_nodes, \n",
        "                                       self.no_of_in_nodes))\n",
        "        rad = 1 / np.sqrt(self.no_of_hidden_nodes)\n",
        "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
        "        self.who = X.rvs((self.no_of_out_nodes, self.no_of_hidden_nodes))\n",
        "        \n",
        "    ##Neural net architecture defining\n",
        "    def train(self, input_vector, target_vector):\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        target_vector = np.array(target_vector, ndmin=2).T\n",
        "        output_vector1 = np.dot(self.wih, input_vector)\n",
        "        output_hidden = activation_function(output_vector1)\n",
        "        output_vector2 = np.dot(self.who, output_hidden)\n",
        "        output_network = activation_function(output_vector2)\n",
        "        output_errors = target_vector - output_network\n",
        "        # update the weights:\n",
        "        tmp = output_errors * output_network * (1.0 - output_network)     \n",
        "        tmp = self.learning_rate  * np.dot(tmp, output_hidden.T)\n",
        "        self.who += tmp\n",
        "        # calculate hidden errors:\n",
        "        hidden_errors = np.dot(self.who.T, output_errors)\n",
        "        # update the weights:\n",
        "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\n",
        "        self.wih += self.learning_rate * np.dot(tmp, input_vector.T)\n",
        "        \n",
        "    def run(self, input_vector):\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        output_vector = np.dot(self.wih, input_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "        output_vector = np.dot(self.who, output_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "        return output_vector\n",
        "\n",
        "    ##Functions for model evaluation     \n",
        "    def confusion_matrix(self, data_array, labels):\n",
        "        cm = np.zeros((10, 10), int)\n",
        "        for i in range(len(data_array)):\n",
        "            res = self.run(data_array[i])\n",
        "            res_max = res.argmax()\n",
        "            target = labels[i][0]\n",
        "            cm[res_max, int(target)] += 1\n",
        "        return cm    \n",
        "\n",
        "    def precision(self, label, confusion_matrix):\n",
        "        col = confusion_matrix[:, label]\n",
        "        return confusion_matrix[label, label] / col.sum()\n",
        "    \n",
        "    def recall(self, label, confusion_matrix):\n",
        "        row = confusion_matrix[label, :]\n",
        "        return confusion_matrix[label, label] / row.sum()\n",
        "        \n",
        "    \n",
        "    def evaluate(self, data, labels):\n",
        "        corrects, wrongs = 0, 0\n",
        "        for i in range(len(data)):\n",
        "            res = self.run(data[i])\n",
        "            res_max = res.argmax()\n",
        "            if res_max == labels[i]:\n",
        "                corrects += 1\n",
        "            else:\n",
        "                wrongs += 1\n",
        "        return corrects, wrongs"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_8_J-oM0ejy"
      },
      "source": [
        "image_pixels = image_size * image_size\n",
        "ANN = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
        "                    no_of_out_nodes = 10, \n",
        "                    no_of_hidden_nodes = 100,\n",
        "                    learning_rate = 0.1)\n",
        "    \n",
        "for i in range(len(train_imgs)):\n",
        "    ANN.train(train_imgs[i], train_labels_one_hot[i])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyZljA3C0xTP",
        "outputId": "e136e381-2adb-4d48-8b60-c96025b5c721"
      },
      "source": [
        "for i in range(20):\n",
        "    res = ANN.run(test_imgs[i])\n",
        "    print(test_labels[i], np.argmax(res), np.max(res))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.] 6 0.9926932344588864\n",
            "[9.] 9 0.9913797185972738\n",
            "[5.] 5 0.9445238972490092\n",
            "[7.] 7 0.9851791952708082\n",
            "[9.] 9 0.978272918756872\n",
            "[2.] 2 0.9617343090986648\n",
            "[3.] 3 0.5686407072766435\n",
            "[3.] 8 0.3601824401597631\n",
            "[7.] 7 0.9948749594063719\n",
            "[0.] 0 0.9722486734678008\n",
            "[6.] 6 0.9632144059847311\n",
            "[9.] 9 0.9858178540215229\n",
            "[1.] 1 0.7173582686688664\n",
            "[8.] 8 0.7352715942113288\n",
            "[2.] 2 0.8936194717906749\n",
            "[4.] 4 0.928082021421061\n",
            "[1.] 1 0.93383851017551\n",
            "[9.] 9 0.7021827325357576\n",
            "[4.] 4 0.9023338447346513\n",
            "[1.] 1 0.5623171464649188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnhYdZJZ4pLn",
        "outputId": "ad0c3761-bd4e-438c-fc71-e1c4b0a7e6a0"
      },
      "source": [
        "corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\n",
        "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
        "corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\n",
        "print(\"accuracy: test\", corrects / ( corrects + wrongs))\n",
        "print(80*\"-\")\n",
        "print(\"Confusion matrix\")\n",
        "print(16*\"-\")\n",
        "cm = ANN.confusion_matrix(train_imgs, train_labels)\n",
        "print(cm)\n",
        "print(80*\"-\")\n",
        "print(\"Precision and recall scores\")\n",
        "print(25*\"-\")\n",
        "for i in range(10):\n",
        "    print(\"digit: \", i, \"precision: \", ANN.precision(i, cm), \"recall: \", ANN.recall(i, cm))\n",
        "print(80*\"-\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy train:  0.9448511904761905\n",
            "accuracy: test 0.9372619047619047\n",
            "--------------------------------------------------------------------------------\n",
            "Confusion matrix\n",
            "----------------\n",
            "[[3275    1   51   26   11   28   44   16   34   21]\n",
            " [   0 3641    8    8    5    4    3   17   36    8]\n",
            " [   1    8 3109   39    9    3    7   38   19    2]\n",
            " [   4   23   32 3223    2   49    1   11   62   45]\n",
            " [   5    5   32    1 2993   18    6   15   12   44]\n",
            " [   4   13    8   91    5 2899   39    6   65   24]\n",
            " [  12    3   29    5   30   26 3196    3   24    0]\n",
            " [   0    9   31   25    8    2    0 3339    8   38]\n",
            " [   7   12   32   18    3    7    2    5 2907    7]\n",
            " [   3    7   16   51  150   30    0   78  103 3165]]\n",
            "--------------------------------------------------------------------------------\n",
            "Precision and recall scores\n",
            "----------------\n",
            "digit:  0 precision:  0.9891271519178496 recall:  0.9338465925292273\n",
            "digit:  1 precision:  0.9782375067168189 recall:  0.9761394101876676\n",
            "digit:  2 precision:  0.9286140979689367 recall:  0.9610510046367852\n",
            "digit:  3 precision:  0.9242902208201893 recall:  0.9336616454229433\n",
            "digit:  4 precision:  0.9306592039800995 recall:  0.9559246247205365\n",
            "digit:  5 precision:  0.9455316373124593 recall:  0.9191502853519341\n",
            "digit:  6 precision:  0.9690721649484536 recall:  0.9603365384615384\n",
            "digit:  7 precision:  0.9464285714285714 recall:  0.965028901734104\n",
            "digit:  8 precision:  0.8889908256880734 recall:  0.969\n",
            "digit:  9 precision:  0.943649373881932 recall:  0.8784346378018318\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAWD6j5t43Hc",
        "outputId": "6f157a3a-83b8-4b39-b09c-7b6ef645e6a1"
      },
      "source": [
        "epochs = 3\n",
        "neural_net = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
        "                   no_of_out_nodes = 10, \n",
        "                   no_of_hidden_nodes = 100,\n",
        "                   learning_rate = 0.1)\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    print(\"epoch: \", epoch)\n",
        "    for i in range(len(train_imgs)):\n",
        "        neural_net.train(train_imgs[i], \n",
        "                 train_labels_one_hot[i])\n",
        "  \n",
        "    corrects, wrongs = neural_net.evaluate(train_imgs, train_labels)\n",
        "    print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
        "    corrects, wrongs = neural_net.evaluate(test_imgs, test_labels)\n",
        "    print(\"accuracy: test\", corrects / ( corrects + wrongs))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "accuracy train:  0.94875\n",
            "accuracy: test 0.9420238095238095\n",
            "epoch:  1\n",
            "accuracy train:  0.9650595238095238\n",
            "accuracy: test 0.9529761904761904\n",
            "epoch:  2\n",
            "accuracy train:  0.9719047619047619\n",
            "accuracy: test 0.9602380952380952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibMao8MIFGYy"
      },
      "source": [
        "##With dropout\n",
        "import random\n",
        "# from scipy.special import expit as activation_function\n",
        "from scipy.stats import truncnorm\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.e ** -x)\n",
        "    # return np.maximum(0,x)\n",
        "\n",
        "activation_function = sigmoid\n",
        "\n",
        "\n",
        "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
        "    return truncnorm(\n",
        "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, \n",
        "                 no_of_in_nodes, \n",
        "                 no_of_out_nodes, \n",
        "                 no_of_hidden_nodes,\n",
        "                 learning_rate,\n",
        "                 bias=None\n",
        "                ):  \n",
        "\n",
        "        self.no_of_in_nodes = no_of_in_nodes\n",
        "        self.no_of_out_nodes = no_of_out_nodes       \n",
        "        self.no_of_hidden_nodes = no_of_hidden_nodes          \n",
        "        self.learning_rate = learning_rate \n",
        "        self.bias = bias\n",
        "        self.create_weight_matrices()\n",
        "        \n",
        "    def create_weight_matrices(self):\n",
        "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
        "        \n",
        "        bias_node = 1 if self.bias else 0\n",
        "\n",
        "        n = (self.no_of_in_nodes + bias_node) * self.no_of_hidden_nodes\n",
        "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
        "        self.wih = X.rvs(n).reshape((self.no_of_hidden_nodes, \n",
        "                                                   self.no_of_in_nodes + bias_node))\n",
        "\n",
        "        n = (self.no_of_hidden_nodes + bias_node) * self.no_of_out_nodes\n",
        "        X = truncated_normal(mean=2, sd=1, low=-0.5, upp=0.5)\n",
        "        self.who = X.rvs(n).reshape((self.no_of_out_nodes, \n",
        "                                                    (self.no_of_hidden_nodes + bias_node)))\n",
        "\n",
        "    def dropout_weight_matrices(self,\n",
        "                                active_input_percentage=0.70,\n",
        "                                active_hidden_percentage=0.70):\n",
        "        # restore wih array, if it had been used for dropout\n",
        "        self.wih_orig = self.wih.copy()\n",
        "        self.no_of_in_nodes_orig = self.no_of_in_nodes\n",
        "        self.no_of_hidden_nodes_orig = self.no_of_hidden_nodes\n",
        "        self.who_orig = self.who.copy()\n",
        "        \n",
        "\n",
        "        active_input_nodes = int(self.no_of_in_nodes * active_input_percentage)\n",
        "        active_input_indices = sorted(random.sample(range(0, self.no_of_in_nodes), \n",
        "                                      active_input_nodes))\n",
        "        active_hidden_nodes = int(self.no_of_hidden_nodes * active_hidden_percentage)\n",
        "        active_hidden_indices = sorted(random.sample(range(0, self.no_of_hidden_nodes), \n",
        "                                       active_hidden_nodes))\n",
        "        \n",
        "        self.wih = self.wih[:, active_input_indices][active_hidden_indices]       \n",
        "        self.who = self.who[:, active_hidden_indices]\n",
        "        \n",
        "        self.no_of_hidden_nodes = active_hidden_nodes\n",
        "        self.no_of_in_nodes = active_input_nodes\n",
        "        return active_input_indices, active_hidden_indices\n",
        "    \n",
        "    def weight_matrices_reset(self, \n",
        "                              active_input_indices, \n",
        "                              active_hidden_indices): \n",
        "        temp = self.wih_orig.copy()[:,active_input_indices]\n",
        "        temp[active_hidden_indices] = self.wih\n",
        "        self.wih_orig[:, active_input_indices] = temp\n",
        "        self.wih = self.wih_orig.copy()\n",
        "\n",
        "        self.who_orig[:, active_hidden_indices] = self.who\n",
        "        self.who = self.who_orig.copy()\n",
        "        self.no_of_in_nodes = self.no_of_in_nodes_orig\n",
        "        self.no_of_hidden_nodes = self.no_of_hidden_nodes_orig\n",
        " \n",
        "           \n",
        "    \n",
        "    def train_single(self, input_vector, target_vector):\n",
        "        if self.bias:\n",
        "            # adding bias node to the end of the input_vector\n",
        "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
        "\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "        target_vector = np.array(target_vector, ndmin=2).T\n",
        "\n",
        "        output_vector1 = np.dot(self.wih, input_vector)\n",
        "        output_vector_hidden = activation_function(output_vector1)\n",
        "        \n",
        "        if self.bias:\n",
        "            output_vector_hidden = np.concatenate( (output_vector_hidden, [[self.bias]]) )\n",
        "        \n",
        "        output_vector2 = np.dot(self.who, output_vector_hidden)\n",
        "        output_vector_network = activation_function(output_vector2)\n",
        "        \n",
        "        output_errors = target_vector - output_vector_network\n",
        "        # update the weights:\n",
        "        tmp = output_errors * output_vector_network * (1.0 - output_vector_network)     \n",
        "        tmp = self.learning_rate  * np.dot(tmp, output_vector_hidden.T)\n",
        "        self.who += tmp\n",
        "\n",
        "\n",
        "        # calculate hidden errors:\n",
        "        hidden_errors = np.dot(self.who.T, output_errors)\n",
        "        # update the weights:\n",
        "        tmp = hidden_errors * output_vector_hidden * (1.0 - output_vector_hidden)\n",
        "        if self.bias:\n",
        "            x = np.dot(tmp, input_vector.T)[:-1,:] \n",
        "        else:\n",
        "            x = np.dot(tmp, input_vector.T)\n",
        "        self.wih += self.learning_rate * x         \n",
        "        \n",
        "    def train(self, data_array, \n",
        "              labels_one_hot_array,\n",
        "              epochs=1,\n",
        "              active_input_percentage=0.70,\n",
        "              active_hidden_percentage=0.70,\n",
        "              no_of_dropout_tests = 10):\n",
        "\n",
        "        partition_length = int(len(data_array) / no_of_dropout_tests)\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            print(\"epoch: \", epoch)\n",
        "            for start in range(0, len(data_array), partition_length):\n",
        "                active_in_indices, active_hidden_indices = \\\n",
        "                           self.dropout_weight_matrices(active_input_percentage,\n",
        "                                                        active_hidden_percentage)\n",
        "                for i in range(start, start + partition_length):\n",
        "                    self.train_single(data_array[i][active_in_indices], \n",
        "                                     labels_one_hot_array[i]) \n",
        "                    \n",
        "                self.weight_matrices_reset(active_in_indices, active_hidden_indices)\n",
        "\n",
        "    # def confusion_matrix(self, data_array, labels):\n",
        "    #     cm = {}\n",
        "    #     for i in range(len(data_array)):\n",
        "    #         res = self.run(data_array[i])\n",
        "    #         res_max = res.argmax()\n",
        "    #         target = labels[i][0]\n",
        "    #         if (target, res_max) in cm:\n",
        "    #             cm[(target, res_max)] += 1\n",
        "    #         else:\n",
        "    #             cm[(target, res_max)] = 1\n",
        "    #     return cm\n",
        "\n",
        "    def confusion_matrix(self, data_array, labels):\n",
        "        cm = np.zeros((10, 10), int)\n",
        "        for i in range(len(data_array)):\n",
        "            res = self.run(data_array[i])\n",
        "            res_max = res.argmax()\n",
        "            target = labels[i][0]\n",
        "            cm[res_max, int(target)] += 1\n",
        "        return cm \n",
        "\n",
        "    def precision(self, label, confusion_matrix):\n",
        "        col = confusion_matrix[:, label]\n",
        "        return confusion_matrix[label, label] / col.sum()\n",
        "    \n",
        "    def recall(self, label, confusion_matrix):\n",
        "        row = confusion_matrix[label, :]\n",
        "        return confusion_matrix[label, label] / row.sum()\n",
        "    \n",
        "    def run(self, input_vector):\n",
        "        # input_vector can be tuple, list or ndarray   \n",
        "        if self.bias:\n",
        "            # adding bias node to the end of the input_vector\n",
        "            input_vector = np.concatenate( (input_vector, [self.bias]) )\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\n",
        "\n",
        "        output_vector = np.dot(self.wih, input_vector)\n",
        "        output_vector = activation_function(output_vector)  \n",
        "        if self.bias:\n",
        "            output_vector = np.concatenate( (output_vector, [[self.bias]]) )\n",
        "        output_vector = np.dot(self.who, output_vector)\n",
        "        output_vector = activation_function(output_vector)\n",
        "    \n",
        "        return output_vector\n",
        "     \n",
        "    def evaluate(self, data, labels):\n",
        "        corrects, wrongs = 0, 0\n",
        "        for i in range(len(data)):\n",
        "            res = self.run(data[i])\n",
        "            res_max = res.argmax()\n",
        "            if res_max == labels[i]:\n",
        "                corrects += 1\n",
        "            else:\n",
        "                wrongs += 1\n",
        "        return corrects, wrongs\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxF9BvULFOg2",
        "outputId": "735e833d-14ca-4719-fe98-87d2e1e01082"
      },
      "source": [
        "parts = 10\n",
        "partition_length = int(len(train_imgs) / parts)\n",
        "print(partition_length)\n",
        "\n",
        "start = 0\n",
        "for start in range(0, len(train_imgs), partition_length):\n",
        "    print(start, start + partition_length)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3360\n",
            "0 3360\n",
            "3360 6720\n",
            "6720 10080\n",
            "10080 13440\n",
            "13440 16800\n",
            "16800 20160\n",
            "20160 23520\n",
            "23520 26880\n",
            "26880 30240\n",
            "30240 33600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYgtKwE8GDci"
      },
      "source": [
        "image_size = 28 # width and length\n",
        "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
        "image_pixels = image_size * image_size"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2OlcRX_F3Jl",
        "outputId": "329739e9-7152-4bb3-990e-f278f25283bc"
      },
      "source": [
        "epochs = 3\n",
        "\n",
        "simple_network = NeuralNetwork(no_of_in_nodes = image_pixels, \n",
        "                               no_of_out_nodes = 10, \n",
        "                               no_of_hidden_nodes = 100,\n",
        "                               learning_rate = 0.1)\n",
        "    \n",
        "    \n",
        " \n",
        "simple_network.train(train_imgs, \n",
        "                     train_labels_one_hot, \n",
        "                     active_input_percentage=1,\n",
        "                     active_hidden_percentage=1,\n",
        "                     no_of_dropout_tests = 10,\n",
        "                     epochs=epochs)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "epoch:  1\n",
            "epoch:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTuHAomlGXh_",
        "outputId": "6fd68e74-4622-484f-dd38-b9ede1a8ef7c"
      },
      "source": [
        "corrects, wrongs = simple_network.evaluate(train_imgs, train_labels)\n",
        "print(\"accuracy train: \", corrects / ( corrects + wrongs))\n",
        "corrects, wrongs = simple_network.evaluate(test_imgs, test_labels)\n",
        "print(\"accuracy: test\", corrects / ( corrects + wrongs))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy train:  0.8744940476190476\n",
            "accuracy: test 0.8622619047619048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy_R5mfzKKJP",
        "outputId": "6a8dcc26-90bf-4d6d-c71a-99f7b72772de"
      },
      "source": [
        "print(\"Confusion matrix\")\n",
        "print(16*\"-\")\n",
        "cm = simple_network.confusion_matrix(train_imgs, train_labels)\n",
        "print(cm)\n",
        "print(80*\"-\")\n",
        "print(\"Precision and recall scores\")\n",
        "print(28*\"-\")\n",
        "for i in range(10):\n",
        "    print(\"digit: \", i, \"precision: \", simple_network.precision(i, cm), \"recall: \", simple_network.recall(i, cm))\n",
        "print(80*\"-\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "----------------\n",
            "[[3262    5  182   89   56  553  120   47   98   45]\n",
            " [   0 3561   15    2    8   15    2    5   20    2]\n",
            " [   0    5 2749   38    4    8    6   37    6    3]\n",
            " [   5   51  150 3084    5  126    1   81  112   24]\n",
            " [   7    1   40    0 2684   52    7   18   10   15]\n",
            " [   3   15    7   71    3 2023   12    7   34   10]\n",
            " [  14   12  103   25   39  119 3133    6   50    4]\n",
            " [   0    7   23   11    2    2    0 3020    2   13]\n",
            " [   8   30   46   75   16   89    7    4 2660   31]\n",
            " [  12   35   33   92  399   79   10  303  278 3207]]\n",
            "--------------------------------------------------------------------------------\n",
            "Precision and recall scores\n",
            "----------------------------\n",
            "digit:  0 precision:  0.985200845665962 recall:  0.7318824321292349\n",
            "digit:  1 precision:  0.9567436861902203 recall:  0.9809917355371901\n",
            "digit:  2 precision:  0.8210872162485066 recall:  0.9625350140056023\n",
            "digit:  3 precision:  0.8844278749641525 recall:  0.8474855729596042\n",
            "digit:  4 precision:  0.8345771144278606 recall:  0.9470712773465068\n",
            "digit:  5 precision:  0.6598173515981736 recall:  0.925858123569794\n",
            "digit:  6 precision:  0.9499696785930867 recall:  0.8938659058487874\n",
            "digit:  7 precision:  0.8560090702947846 recall:  0.9805194805194806\n",
            "digit:  8 precision:  0.8134556574923547 recall:  0.8968307484828051\n",
            "digit:  9 precision:  0.9561717352415027 recall:  0.720998201438849\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uohCyF9VKCnm"
      },
      "source": [
        "We can see a decline in prediction accuracy after adding dropout. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU9aLK0GXyAZ"
      },
      "source": [
        "## References:\n",
        "https://www.python-course.eu/neural_network_mnist.php </br>\n",
        "https://www.kaggle.com/c/digit-recognizer/data </br>\n",
        "https://www.python-course.eu/neural_networks_with_dropout.php"
      ]
    }
  ]
}